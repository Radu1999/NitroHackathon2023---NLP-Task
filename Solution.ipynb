{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T07:56:33.636288Z","iopub.status.busy":"2023-03-26T07:56:33.635790Z","iopub.status.idle":"2023-03-26T07:56:56.841413Z","shell.execute_reply":"2023-03-26T07:56:56.839995Z","shell.execute_reply.started":"2023-03-26T07:56:33.636245Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import pandas as pd\n","from transformers import AutoTokenizer, BertForSequenceClassification\n","from torch.utils.data import Dataset\n","import wandb\n","import shutil\n","from torch.utils.data import WeightedRandomSampler\n","import os\n","from sklearn.metrics import balanced_accuracy_score\n","import emoji\n","import ast\n","import re"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T07:56:56.850566Z","iopub.status.busy":"2023-03-26T07:56:56.848122Z","iopub.status.idle":"2023-03-26T07:56:57.239996Z","shell.execute_reply":"2023-03-26T07:56:57.238913Z","shell.execute_reply.started":"2023-03-26T07:56:56.850518Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>Final Labels</th>\n","      <th>Id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>@CorinaTomescu05 칉nc캒 nu ...dar am trecut prin...</td>\n","      <td>non-offensive</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>@emosaphicbitch sau rosu ca mine</td>\n","      <td>non-offensive</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>@DanaMinodora Ce frumoasa e탳ti.. Ar캒탵i foarte ...</td>\n","      <td>non-offensive</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Din fericire 칥n extaz!Ai dus covoareleeee?? Pu...</td>\n","      <td>offensive</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cand aveam vreo 5 ani credeam ca romana e sing...</td>\n","      <td>non-offensive</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>@ALETTAOCEANXXXX Ce prin탵es캒 frumoas캒 탳i sexxx...</td>\n","      <td>direct</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>@sandman_II @i0n1ca Ionica din clipa c칙nd te-a...</td>\n","      <td>direct</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Coronavirus Rom칙nia, 29 iunie 2021. 294 de dec...</td>\n","      <td>non-offensive</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>@boobingheluvr te rog eu mai ie탳i din casa</td>\n","      <td>offensive</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>@alexbadea9 Corpul meu e pe modul toamn캒. M캒 i...</td>\n","      <td>non-offensive</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>singura parte din biologie care are drepturi e...</td>\n","      <td>non-offensive</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>@MarkZuckerbelg Nu trebuie s캒 칥탵i fie ru탳ine d...</td>\n","      <td>non-offensive</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Te duci la bemol,din c칙te 탳tiu po탵i primi feri...</td>\n","      <td>non-offensive</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>@GabrielGiurgiu2 @TanarulD Nu stiu care le est...</td>\n","      <td>non-offensive</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>@96Merla @AdrianRaduca Mi-e 칥mi plac femeile n...</td>\n","      <td>descriptive</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>@DanTatulescu Sau poate se teme c캒 칥i sare un ...</td>\n","      <td>non-offensive</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>@metalheadhutao Atunci sadly e탳ti nevoit캒 s캒 l...</td>\n","      <td>non-offensive</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Sincer? Arata ca o cheie fixa, inspirandu-mi i...</td>\n","      <td>non-offensive</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Am licurici in fund de emo탵ie</td>\n","      <td>non-offensive</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>@MGStaking Buna ziua, mul탵umesc pt oportunitat...</td>\n","      <td>non-offensive</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>@TanarulD Nu era nici un pericol. De mici merg...</td>\n","      <td>non-offensive</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>@AdiXs5 dupa update din cate am inteles</td>\n","      <td>non-offensive</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>칥ntr-un anumit mod, pentru a-탵i calma organism...</td>\n","      <td>non-offensive</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>@ChrXss0 @M1SUU_ @zAndyYT @FnCata cristiane vi...</td>\n","      <td>offensive</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Bucure탳teni, va put gunoaiele? Dar de ce nu pu...</td>\n","      <td>offensive</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>@Minminbitch2 nu au pus dansul cu doar intervi...</td>\n","      <td>non-offensive</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>@floarex A탳a s캒 fie 游볙 la fel 칥탵i doresc</td>\n","      <td>non-offensive</td>\n","      <td>26</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>Trippie, Uzi, Juice or Carti</td>\n","      <td>non-offensive</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>@LillyElena Adic캒.... tu ai soare? Pe ce plane...</td>\n","      <td>non-offensive</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>@DanTatulescu @m1ssmadness Ofert캒 de 칥mprumut ...</td>\n","      <td>non-offensive</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>@mochivity bafta multa, eu am 칥nv캒탵at doar ion...</td>\n","      <td>non-offensive</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>@ventixlyre_ ar tr sa dau mute si la toata cuv...</td>\n","      <td>non-offensive</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>cafeaua nu se bea cu lapte , se bea cu mine 游눎</td>\n","      <td>non-offensive</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>E deja diminea탵a 탳i nu am dormit de loc  Nu 탳t...</td>\n","      <td>non-offensive</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>Ceva imi spune ca e mai ieftin decat un caine</td>\n","      <td>non-offensive</td>\n","      <td>34</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>@basarab84 Epoca anilor 60 ,nu seam캒n캒 nici pe...</td>\n","      <td>non-offensive</td>\n","      <td>35</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>@SnooKu @Evolveegg @OfficialRedfear Toti copii...</td>\n","      <td>non-offensive</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>clasa mea si a facut probleme cu directoarea f...</td>\n","      <td>non-offensive</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>vreau o cafea neagr캒 ca inima ta 탳i dulce ca a...</td>\n","      <td>non-offensive</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>singura chestie care m캒 탵ine 칥ntreag캒 la cap e...</td>\n","      <td>offensive</td>\n","      <td>39</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>@e_raluca @wh157l3r @vonderleyen @JosepBorrell...</td>\n","      <td>non-offensive</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>Romanii educati s-au vaccinat! Aplauze! Aaaa, ...</td>\n","      <td>offensive</td>\n","      <td>41</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>@MarmotaDeCampie @simovitty @mariusbmg21 A탳a s...</td>\n","      <td>non-offensive</td>\n","      <td>42</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>@metalheadhutao Arata ca iubirea vie탵ii mele l...</td>\n","      <td>non-offensive</td>\n","      <td>43</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>coaie nu e aici ce pula mea vrei sa 칥탵i zic ma...</td>\n","      <td>offensive</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>@Alin30658433 @SorinGrumazescu M캒 bucur c캒 ai ...</td>\n","      <td>non-offensive</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>Andrei G칥rtofan (Subaru Impreza N15), ajutat d...</td>\n","      <td>non-offensive</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>Ba ok a탳tep탵i pu탵in sa vezi ce se 칥nt칙mpl캒 cu ...</td>\n","      <td>non-offensive</td>\n","      <td>47</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>@LillyElena @IonescuLaura11 Nu este chiar a탳a</td>\n","      <td>non-offensive</td>\n","      <td>48</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>@angelwonie a탳a auzisem 탳i eu dar tot sper ca ...</td>\n","      <td>non-offensive</td>\n","      <td>49</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>Nu e탳ti niciodat캒 prea b캒tr칙n pentru a stabili...</td>\n","      <td>non-offensive</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>@AndreiCismaru Eu nu 탳tiu la ce serve탳te livre...</td>\n","      <td>non-offensive</td>\n","      <td>51</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>@DiarLeaks Bro e탳ti cel mai for탵캒 leaker ! Mer...</td>\n","      <td>non-offensive</td>\n","      <td>52</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>coaie clotilde aia e imbecila grav sa ia banii...</td>\n","      <td>offensive</td>\n","      <td>53</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>@ConsultantaCry1 Stochastic RSI pe 2w arat캒 c캒...</td>\n","      <td>non-offensive</td>\n","      <td>54</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                 Text   Final Labels  Id\n","0   @CorinaTomescu05 칉nc캒 nu ...dar am trecut prin...  non-offensive   0\n","1                    @emosaphicbitch sau rosu ca mine  non-offensive   1\n","2   @DanaMinodora Ce frumoasa e탳ti.. Ar캒탵i foarte ...  non-offensive   2\n","3   Din fericire 칥n extaz!Ai dus covoareleeee?? Pu...      offensive   3\n","4   cand aveam vreo 5 ani credeam ca romana e sing...  non-offensive   4\n","5   @ALETTAOCEANXXXX Ce prin탵es캒 frumoas캒 탳i sexxx...         direct   5\n","6   @sandman_II @i0n1ca Ionica din clipa c칙nd te-a...         direct   6\n","7   Coronavirus Rom칙nia, 29 iunie 2021. 294 de dec...  non-offensive   7\n","8          @boobingheluvr te rog eu mai ie탳i din casa      offensive   8\n","9   @alexbadea9 Corpul meu e pe modul toamn캒. M캒 i...  non-offensive   9\n","10  singura parte din biologie care are drepturi e...  non-offensive  10\n","11  @MarkZuckerbelg Nu trebuie s캒 칥탵i fie ru탳ine d...  non-offensive  11\n","12  Te duci la bemol,din c칙te 탳tiu po탵i primi feri...  non-offensive  12\n","13  @GabrielGiurgiu2 @TanarulD Nu stiu care le est...  non-offensive  13\n","14  @96Merla @AdrianRaduca Mi-e 칥mi plac femeile n...    descriptive  14\n","15  @DanTatulescu Sau poate se teme c캒 칥i sare un ...  non-offensive  15\n","16  @metalheadhutao Atunci sadly e탳ti nevoit캒 s캒 l...  non-offensive  16\n","17  Sincer? Arata ca o cheie fixa, inspirandu-mi i...  non-offensive  17\n","18                      Am licurici in fund de emo탵ie  non-offensive  18\n","19  @MGStaking Buna ziua, mul탵umesc pt oportunitat...  non-offensive  19\n","20  @TanarulD Nu era nici un pericol. De mici merg...  non-offensive  20\n","21            @AdiXs5 dupa update din cate am inteles  non-offensive  21\n","22  칥ntr-un anumit mod, pentru a-탵i calma organism...  non-offensive  22\n","23  @ChrXss0 @M1SUU_ @zAndyYT @FnCata cristiane vi...      offensive  23\n","24  Bucure탳teni, va put gunoaiele? Dar de ce nu pu...      offensive  24\n","25  @Minminbitch2 nu au pus dansul cu doar intervi...  non-offensive  25\n","26            @floarex A탳a s캒 fie 游볙 la fel 칥탵i doresc  non-offensive  26\n","27                       Trippie, Uzi, Juice or Carti  non-offensive  27\n","28  @LillyElena Adic캒.... tu ai soare? Pe ce plane...  non-offensive  28\n","29  @DanTatulescu @m1ssmadness Ofert캒 de 칥mprumut ...  non-offensive  29\n","30  @mochivity bafta multa, eu am 칥nv캒탵at doar ion...  non-offensive  30\n","31  @ventixlyre_ ar tr sa dau mute si la toata cuv...  non-offensive  31\n","32      cafeaua nu se bea cu lapte , se bea cu mine 游눎  non-offensive  32\n","33  E deja diminea탵a 탳i nu am dormit de loc  Nu 탳t...  non-offensive  33\n","34      Ceva imi spune ca e mai ieftin decat un caine  non-offensive  34\n","35  @basarab84 Epoca anilor 60 ,nu seam캒n캒 nici pe...  non-offensive  35\n","36  @SnooKu @Evolveegg @OfficialRedfear Toti copii...  non-offensive  36\n","37  clasa mea si a facut probleme cu directoarea f...  non-offensive  37\n","38  vreau o cafea neagr캒 ca inima ta 탳i dulce ca a...  non-offensive  38\n","39  singura chestie care m캒 탵ine 칥ntreag캒 la cap e...      offensive  39\n","40  @e_raluca @wh157l3r @vonderleyen @JosepBorrell...  non-offensive  40\n","41  Romanii educati s-au vaccinat! Aplauze! Aaaa, ...      offensive  41\n","42  @MarmotaDeCampie @simovitty @mariusbmg21 A탳a s...  non-offensive  42\n","43  @metalheadhutao Arata ca iubirea vie탵ii mele l...  non-offensive  43\n","44  coaie nu e aici ce pula mea vrei sa 칥탵i zic ma...      offensive  44\n","45  @Alin30658433 @SorinGrumazescu M캒 bucur c캒 ai ...  non-offensive  45\n","46  Andrei G칥rtofan (Subaru Impreza N15), ajutat d...  non-offensive  46\n","47  Ba ok a탳tep탵i pu탵in sa vezi ce se 칥nt칙mpl캒 cu ...  non-offensive  47\n","48      @LillyElena @IonescuLaura11 Nu este chiar a탳a  non-offensive  48\n","49  @angelwonie a탳a auzisem 탳i eu dar tot sper ca ...  non-offensive  49\n","50  Nu e탳ti niciodat캒 prea b캒tr칙n pentru a stabili...  non-offensive  50\n","51  @AndreiCismaru Eu nu 탳tiu la ce serve탳te livre...  non-offensive  51\n","52  @DiarLeaks Bro e탳ti cel mai for탵캒 leaker ! Mer...  non-offensive  52\n","53  coaie clotilde aia e imbecila grav sa ia banii...      offensive  53\n","54  @ConsultantaCry1 Stochastic RSI pe 2w arat캒 c캒...  non-offensive  54"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["## Incarcare dataset\n","df = pd.read_csv('/kaggle/input/custom/train_data.csv')\n","df.head(55)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T07:56:57.247178Z","iopub.status.busy":"2023-03-26T07:56:57.244653Z","iopub.status.idle":"2023-03-26T07:56:57.257286Z","shell.execute_reply":"2023-03-26T07:56:57.255155Z","shell.execute_reply.started":"2023-03-26T07:56:57.247135Z"},"trusted":true},"outputs":[],"source":["def text_without_emojis():\n","    text_noemoji = []\n","    for i in df.index:\n","        line = df['Text'].iloc[i]\n","        emojis = emoji.emoji_list(line)\n","        for emoji_dict in emojis:\n","            emoji_str = emoji_dict.get('emoji')\n","            line = re.sub(emoji_str, '', line)\n","        text_noemoji.append(line)\n","    return text_noemoji"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T07:56:57.273330Z","iopub.status.busy":"2023-03-26T07:56:57.268433Z","iopub.status.idle":"2023-03-26T07:56:57.283174Z","shell.execute_reply":"2023-03-26T07:56:57.282037Z","shell.execute_reply.started":"2023-03-26T07:56:57.273282Z"},"trusted":true},"outputs":[],"source":["def text_without_mentions():\n","    text_nomentions = [re.sub(r'@\\S+', '', line) for line in df['Text']]\n","    return text_nomentions"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T07:56:57.292729Z","iopub.status.busy":"2023-03-26T07:56:57.289140Z","iopub.status.idle":"2023-03-26T07:56:57.302721Z","shell.execute_reply":"2023-03-26T07:56:57.301350Z","shell.execute_reply.started":"2023-03-26T07:56:57.292390Z"},"trusted":true},"outputs":[],"source":["def weird_characters():\n","    chars = {character for line in df['Text'] for character in line if not re.search(r'[a-zA-Z0-9탳탵칥칙캒탲탴츽캑칉\\s_-]+', character)}\n","    return chars"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T07:56:57.310924Z","iopub.status.busy":"2023-03-26T07:56:57.308012Z","iopub.status.idle":"2023-03-26T07:56:57.321572Z","shell.execute_reply":"2023-03-26T07:56:57.320127Z","shell.execute_reply.started":"2023-03-26T07:56:57.310884Z"},"trusted":true},"outputs":[],"source":["def check_with_dictionary(file_name):\n","    text_cleaned = []\n","    with open(file_name, \"r\", encoding='UTF-8') as data:\n","        dictionary = ast.literal_eval(data.read())\n","        # print(dictionary)\n","        # print(type(dictionary))\n","        for line in df['Text']:\n","            for key in dictionary:\n","                if key != dictionary[key]:\n","                    while line.find(key) != -1:\n","                        line = line.replace(key, dictionary[key])\n","            text_cleaned.append(line)\n","    return text_cleaned"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T07:56:57.330365Z","iopub.status.busy":"2023-03-26T07:56:57.327819Z","iopub.status.idle":"2023-03-26T07:56:57.340564Z","shell.execute_reply":"2023-03-26T07:56:57.339230Z","shell.execute_reply.started":"2023-03-26T07:56:57.330322Z"},"trusted":true},"outputs":[],"source":["def clean_non_ascii():\n","    text_cleaned = []\n","    for line in df['Text']:\n","        tokens = word_tokenize(line)\n","        clean_tokens = [token for token in tokens if token.isascii() or re.search(r'[/S탳탵칥칙캒탲탴츽캑칉/S]',token)]\n","        clean_text = \" \".join(clean_tokens)\n","        text_cleaned.append(clean_text)\n","    return text_cleaned"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T07:56:57.347404Z","iopub.status.busy":"2023-03-26T07:56:57.345764Z","iopub.status.idle":"2023-03-26T07:56:57.359408Z","shell.execute_reply":"2023-03-26T07:56:57.357994Z","shell.execute_reply.started":"2023-03-26T07:56:57.347362Z"},"trusted":true},"outputs":[],"source":["def clean_non_alphanumerical():\n","    text_cleaned = []\n","    dictionary = weird_characters()\n","    for line in df['Text']:\n","        for elem in dictionary:\n","            while line.find(elem) != -1:\n","                line = line.replace(elem, '')\n","        text_cleaned.append(line)\n","    return text_cleaned"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T07:56:57.367960Z","iopub.status.busy":"2023-03-26T07:56:57.367461Z","iopub.status.idle":"2023-03-26T07:56:57.385379Z","shell.execute_reply":"2023-03-26T07:56:57.383685Z","shell.execute_reply.started":"2023-03-26T07:56:57.367919Z"},"trusted":true},"outputs":[],"source":["def lowercase_text():\n","    text_lowercase = []\n","    for line in df['Text']:\n","        line = line.replace('_', ' ')\n","        if not re.search(r'[탲탴츽캑칉]+', line):\n","            line = line.lower()\n","        else:\n","            line = line.replace(\"탴\", \"탵\").replace(\"탲\", \"탳\").replace(\"칉\", \"칥\").replace(\"캑\", \"캒\").replace(\"츽\", \"칙\")\n","        text_lowercase.append(line)\n","\n","    return text_lowercase"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T07:56:57.395757Z","iopub.status.busy":"2023-03-26T07:56:57.390741Z","iopub.status.idle":"2023-03-26T07:57:00.174739Z","shell.execute_reply":"2023-03-26T07:57:00.173664Z","shell.execute_reply.started":"2023-03-26T07:56:57.395711Z"},"trusted":true},"outputs":[],"source":["df['Text'] = text_without_emojis()\n","df['Text'] = text_without_mentions()\n","# df['Text'] = check_with_dictionary('character map/full_replace.txt')\n","# df['Text'] = clean_non_ascii()\n","# df['Text'] = clean_non_alphanumerical()\n","# df['Text'] = lowercase_text()\n","\n","df.to_csv('/kaggle/working/train_data_noemoji_nomentions.csv', index=False)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T07:57:00.177333Z","iopub.status.busy":"2023-03-26T07:57:00.176187Z","iopub.status.idle":"2023-03-26T07:57:00.195106Z","shell.execute_reply":"2023-03-26T07:57:00.193757Z","shell.execute_reply.started":"2023-03-26T07:57:00.177290Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>Final Labels</th>\n","      <th>Id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>칉nc캒 nu ...dar am trecut prin...28.... s캒 fii...</td>\n","      <td>non-offensive</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sau rosu ca mine</td>\n","      <td>non-offensive</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Ce frumoasa e탳ti.. Ar캒탵i foarte bine frumoaso</td>\n","      <td>non-offensive</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Din fericire 칥n extaz!Ai dus covoareleeee?? Pu...</td>\n","      <td>offensive</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cand aveam vreo 5 ani credeam ca romana e sing...</td>\n","      <td>non-offensive</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Ce prin탵es캒 frumoas캒 탳i sexxxxyyy e탳ti</td>\n","      <td>direct</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Ionica din clipa c칙nd te-am v캒zut pentru pri...</td>\n","      <td>direct</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Coronavirus Rom칙nia, 29 iunie 2021. 294 de dec...</td>\n","      <td>non-offensive</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>te rog eu mai ie탳i din casa</td>\n","      <td>offensive</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Corpul meu e pe modul toamn캒. M캒 ia somnul de...</td>\n","      <td>non-offensive</td>\n","      <td>9</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                Text   Final Labels  Id\n","0   칉nc캒 nu ...dar am trecut prin...28.... s캒 fii...  non-offensive   0\n","1                                   sau rosu ca mine  non-offensive   1\n","2      Ce frumoasa e탳ti.. Ar캒탵i foarte bine frumoaso  non-offensive   2\n","3  Din fericire 칥n extaz!Ai dus covoareleeee?? Pu...      offensive   3\n","4  cand aveam vreo 5 ani credeam ca romana e sing...  non-offensive   4\n","5             Ce prin탵es캒 frumoas캒 탳i sexxxxyyy e탳ti         direct   5\n","6    Ionica din clipa c칙nd te-am v캒zut pentru pri...         direct   6\n","7  Coronavirus Rom칙nia, 29 iunie 2021. 294 de dec...  non-offensive   7\n","8                        te rog eu mai ie탳i din casa      offensive   8\n","9   Corpul meu e pe modul toamn캒. M캒 ia somnul de...  non-offensive   9"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["## Testare dataset\n","#df = pd.read_csv('dataset/train_data_noemoji.csv')\n","#df = pd.read_csv('dataset/train_data_noemoji_nomentions.csv')\n","df.head(10)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T07:57:00.197713Z","iopub.status.busy":"2023-03-26T07:57:00.197171Z","iopub.status.idle":"2023-03-26T07:57:00.207105Z","shell.execute_reply":"2023-03-26T07:57:00.205933Z","shell.execute_reply.started":"2023-03-26T07:57:00.197652Z"},"trusted":true},"outputs":[],"source":["class SexismDetectionModel(nn.Module):\n","    def __init__(self, model_name, num_classes):\n","        super().__init__()\n","        self.bert_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_classes,\n","                                                                        return_dict=False)\n","\n","    def forward(self, x):\n","        return self.bert_model(x)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T07:57:00.209362Z","iopub.status.busy":"2023-03-26T07:57:00.208917Z","iopub.status.idle":"2023-03-26T07:57:00.221723Z","shell.execute_reply":"2023-03-26T07:57:00.220584Z","shell.execute_reply.started":"2023-03-26T07:57:00.209320Z"},"trusted":true},"outputs":[],"source":["class SexismDataset(Dataset):\n","\n","    def __init__(self, model_name,  file, test=False):\n","        data = pd.read_csv(file)\n","        self.text = data[\"Text\"].tolist()\n","        self.label_mapping = {\n","            'direct': 0,\n","            'descriptive': 1,\n","            'reporting': 2,\n","            'offensive': 3,\n","            'non-offensive': 4\n","        }\n","        self.padding = 64\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n","        self.test = test\n","        self.maximum = 0\n","        self.count = 0\n","        if not test:\n","            self.labels = data[\"Final Labels\"].tolist()\n","\n","    def __len__(self):\n","        return len(self.text)\n","\n","    def __getitem__(self, item):\n","\n","         \n","        input_ids = self.tokenizer.encode(self.text[item], add_special_tokens=True, return_tensors=\"pt\",\n","                                          max_length=self.padding,\n","                                          padding='max_length',\n","                                          truncation=True).view(-1)\n","        if not self.test:\n","            return input_ids, self.label_mapping[self.labels[item]]\n","        return input_ids"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T07:57:00.224270Z","iopub.status.busy":"2023-03-26T07:57:00.223542Z","iopub.status.idle":"2023-03-26T07:57:00.259974Z","shell.execute_reply":"2023-03-26T07:57:00.258656Z","shell.execute_reply.started":"2023-03-26T07:57:00.224222Z"},"trusted":true},"outputs":[],"source":["def save_ckp(state, is_best, checkpoint_dir, best_model_dir, num=None):\n","    if num is not None:  \n","        f_path = checkpoint_dir + f'/checkpoint{num}.pt'\n","    else:\n","        f_path = checkpoint_dir + f'/checkpoint.pt'\n","    torch.save(state, f_path)\n","    if is_best:\n","        if num is not None:  \n","            best_fpath = best_model_dir + f'/best_model{num}.pt'\n","        else:\n","            best_fpath = best_model_dir + f'/best_model.pt'\n","        shutil.copyfile(f_path, best_fpath)\n","\n","\n","def load_ckp(checkpoint_fpath, model, optimizer):\n","    checkpoint = torch.load(checkpoint_fpath)\n","    model.load_state_dict(checkpoint['state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    return model, optimizer, checkpoint['epoch'], checkpoint['best_acc']\n","\n","\n","def get_weighted_sampler(dataset):\n","    class_indices = {}\n","    for i in range(len(dataset)):\n","        _, label = dataset[i]\n","        if label not in class_indices:\n","            class_indices[label] = []\n","        class_indices[label].append(i)\n","\n","    class_weights = {}\n","    for label in class_indices:\n","        class_weights[label] = 1 / len(class_indices[label])\n","\n","    weights = [class_weights[label] for _, label in dataset]\n","    oversample_sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n","\n","    return oversample_sampler\n","\n","\n","class ModelTrainer:\n","\n","    def __init__(self, device, model, criterion, optimizer, dataset, validation_split=.2,\n","                 batch_size=32, shuffle_dataset=True,\n","                 random_seed=42, resume_from_checkpoint=False, project_name=\"Training\", architecture=\"Unknown\",\n","                 num_epochs=25, initial_lr=None, num_classes=None, weighted_sampler=False):\n","\n","        os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n","        os.environ['TORCH_USE_CUDA_DSA'] = '1'\n","\n","        if resume_from_checkpoint:\n","            self.model, self.optimizer, self.start_epoch, self.best_acc = load_ckp(\n","                'checkpoint/checkpoint.pt',\n","                model, optimizer)\n","        else:\n","            self.model = model\n","            self.optimizer = optimizer\n","            self.start_epoch = 0\n","            self.best_acc = 0.0\n","\n","        self.model.to(device)\n","        self.criterion = criterion\n","\n","        self.dataset = dataset\n","        self.shuffle_dataset = shuffle_dataset\n","        self.random_seed = random_seed\n","        self.dataset_size = len(dataset)\n","        self.validation_split = validation_split\n","        self.device = device\n","        self.batch_size = batch_size\n","        self.lr_scheduler = None\n","        self.epochs = num_epochs\n","        self.nr_batch_report = 5\n","        self.num_classes = num_classes\n","\n","        test_size = int(self.validation_split * len(dataset))\n","        train_size = len(dataset)\n","        train_dataset = dataset\n","        _, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - test_size, test_size])\n","\n","        if not weighted_sampler:\n","            train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n","                                                       num_workers=0, drop_last=True)\n","        else:\n","            weighted_sampler = get_weighted_sampler(train_dataset)\n","            train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n","                                                       sampler=weighted_sampler,\n","                                                       num_workers=0, drop_last=True)\n","\n","        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n","                                                  num_workers=0, drop_last=True)\n","\n","        self.dataloaders = {'train': train_loader,\n","                            'val': test_loader}\n","\n","        self.dataset_sizes = {\"train\": train_size, \"val\": test_size}\n","\n","        torch.backends.cudnn.benchmark = True\n","\n","        torch.backends.cuda.matmul.allow_tf32 = True\n","\n","        # The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n","        torch.backends.cudnn.allow_tf32 = True\n","\n","        wandb.init(\n","            # set the wandb project where this run will be logged\n","            project=project_name,\n","\n","            # track hyper parameters and run metadata\n","            config={\n","                \"architecture\": architecture,\n","                \"epochs\": num_epochs,\n","                \"nr_batch_report\": self.nr_batch_report,\n","                \"initial_lr\": initial_lr if initial_lr else \"Unknown\",\n","                \"batch_size\": self.batch_size\n","            }\n","        )\n","\n","        wandb.log({\"train_size\": train_size, \"test_size\": test_size})\n","\n","    def set_lr_scheduler(self, scheduler):\n","        self.lr_scheduler = scheduler\n","\n","    def train_model(self):\n","        scaler = torch.cuda.amp.GradScaler()\n","        \n","        \n","        for epoch in range(self.start_epoch, self.epochs):\n","            # Each epoch has a training and validation phase\n","            wandb.log({\n","                \"epoch\": epoch\n","            })\n","            for phase in ['train', 'val']:\n","                torch.cuda.empty_cache()\n","                if phase == 'train':\n","                    self.model.train()  # Set model to training mode\n","                else:\n","                    self.model.eval()  # Set model to evaluate mode\n","\n","                running_loss = 0.0\n","                running_corrects = 0\n","\n","                # Iterate over data.\n","                y_true = []\n","                y_pred = []\n","                \n","                for batch_idx, (inputs, labels) in enumerate(self.dataloaders[phase]):\n","                    inputs = inputs.to(self.device)\n","                    labels = torch.as_tensor(labels).to(self.device)\n","\n","                    # zero the parameter gradients\n","                    self.optimizer.zero_grad()\n","\n","                    # forward\n","                    with torch.cuda.amp.autocast():\n","                        with torch.set_grad_enabled(phase == 'train'):\n","                            outputs = self.model(inputs)\n","                        if type(outputs) is tuple:\n","                            outputs = outputs[0]\n","                        loss = self.criterion(outputs, labels)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        scaler.scale(loss).backward()\n","                        scaler.step(self.optimizer)\n","                        scaler.update()\n","\n","                        if batch_idx % self.nr_batch_report == 0:\n","                            wandb.log({\"loss\": loss.item()})\n","                            if self.lr_scheduler:\n","                                wandb.log({\"lr\": self.lr_scheduler.get_last_lr()[-1]})\n","                                self.lr_scheduler.step()\n","\n","                    # statistics\n","                    running_loss += loss.item() * inputs.size(0)\n","                    _, preds = torch.max(outputs, 1)\n","                    y_pred.extend(preds.tolist())\n","                    y_true.extend(labels.tolist())\n","\n","                epoch_acc = balanced_accuracy_score(y_true, y_pred)\n","                if phase == 'val':\n","                    wandb.log({\n","                        \"epoch_acc_val\": epoch_acc,\n","                    })\n","                else:\n","                    epoch_loss = running_loss / self.dataset_sizes[phase]\n","                    wandb.log({\n","                        \"epoch_acc_train\": epoch_acc,\n","                        \"epoch_loss_train\": epoch_loss,\n","                    })\n","\n","                checkpoint = {\n","                    'epoch': epoch + 1,\n","                    'state_dict': self.model.state_dict(),\n","                    'optimizer': self.optimizer.state_dict(),\n","                    'best_acc': self.best_acc\n","                }\n","\n","                # deep copy the model\n","                if phase == 'val' and epoch_acc > self.best_acc:\n","                    save_ckp(checkpoint, True, \"checkpoint\", 'best_model')\n","                    self.best_acc = epoch_acc\n","                    wandb.log({\n","                        \"best_acc_val\": self.best_acc\n","                    })\n","                save_ckp(checkpoint, False, \"checkpoint\", 'best_model')\n","        return self.model"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T07:57:00.264236Z","iopub.status.busy":"2023-03-26T07:57:00.263881Z","iopub.status.idle":"2023-03-26T07:57:00.295861Z","shell.execute_reply":"2023-03-26T07:57:00.294744Z","shell.execute_reply.started":"2023-03-26T07:57:00.264205Z"},"trusted":true},"outputs":[],"source":["class ModelTrainer2:\n","\n","    def __init__(self, device, model, criterion, optimizer, dataset, validation_split=.2,\n","                 batch_size=32, shuffle_dataset=True,\n","                 random_seed=42, resume_from_checkpoint=False, project_name=\"Training\", architecture=\"Unknown\",\n","                 num_epochs=25, initial_lr=None, num_classes=None, weighted_sampler=False):\n","\n","        os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n","        os.environ['TORCH_USE_CUDA_DSA'] = '1'\n","\n","        if resume_from_checkpoint:\n","            self.model, self.optimizer, self.start_epoch, self.best_acc = load_ckp(\n","                'checkpoint/checkpoint.pt',\n","                model, optimizer)\n","        else:\n","            self.model = model\n","            self.optimizer = optimizer\n","            self.start_epoch = 0\n","            self.best_acc = 0.0\n","\n","        self.model.to(device)\n","        self.criterion = criterion\n","\n","        self.dataset = dataset\n","        self.shuffle_dataset = shuffle_dataset\n","        self.random_seed = random_seed\n","        self.dataset_size = len(dataset)\n","        self.validation_split = validation_split\n","        self.device = device\n","        self.batch_size = batch_size\n","        self.lr_scheduler = None\n","        self.epochs = num_epochs\n","        self.nr_batch_report = 5\n","        self.num_classes = num_classes \n","\n","        test_size = int(self.validation_split * len(dataset))\n","        train_size = len(dataset)\n","        train_dataset = dataset\n","        _, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - test_size, test_size])\n","\n","        if not weighted_sampler:\n","            train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n","                                                       num_workers=0, drop_last=True)\n","        else:\n","            self.weighted_sampler = get_weighted_sampler(train_dataset)\n","            train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n","                                                       sampler=self.weighted_sampler,\n","                                                       num_workers=0, drop_last=True)\n","\n","        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n","                                                  num_workers=0, drop_last=True)\n","\n","        self.dataloaders = {'train': train_loader,\n","                            'val': test_loader}\n","\n","        self.dataset_sizes = {\"train\": train_size, \"val\": test_size}\n","\n","        torch.backends.cudnn.benchmark = True\n","\n","        torch.backends.cuda.matmul.allow_tf32 = True\n","\n","        # The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n","        torch.backends.cudnn.allow_tf32 = True\n","\n","        wandb.init(\n","            # set the wandb project where this run will be logged\n","            project=project_name,\n","\n","            # track hyper parameters and run metadata\n","            config={\n","                \"architecture\": architecture,\n","                \"epochs\": num_epochs,\n","                \"nr_batch_report\": self.nr_batch_report,\n","                \"initial_lr\": initial_lr if initial_lr else \"Unknown\",\n","                \"batch_size\": self.batch_size\n","            }\n","        )\n","\n","        wandb.log({\"train_size\": train_size, \"test_size\": test_size})\n","\n","    def set_lr_scheduler(self, scheduler):\n","        self.lr_scheduler = scheduler\n","\n","    def train_models(self):\n","        model_name = \"dumitrescustefan/bert-base-romanian-cased-v1\"\n","        dataset = SexismDataset(model_name, \"/kaggle/input/custom/train_data_final.csv\")\n","        for i in range(10):\n","            scaler = torch.cuda.amp.GradScaler()\n","\n","            model = SexismDetectionModel(model_name, num_classes=5).to(self.device)\n","            optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n","            for epoch in range(2):\n","                # Each epoch has a training and validation phase\n","                wandb.log({\n","                    \"epoch\": epoch\n","                })\n","                for phase in ['train', 'val']:\n","                    torch.cuda.empty_cache()\n","                    if phase == 'train':\n","                        model.train()  # Set model to training mode\n","                    else:\n","                        model.eval()  # Set model to evaluate mode\n","\n","                    running_loss = 0.0\n","                    running_corrects = 0\n","\n","                    # Iterate over data.\n","                    y_true = []\n","                    y_pred = []\n","\n","                    for batch_idx, (inputs, labels) in enumerate(self.dataloaders[phase]):\n","                        inputs = inputs.to(self.device)\n","                        labels = torch.as_tensor(labels).to(self.device)\n","\n","                        # zero the parameter gradients\n","                        optimizer.zero_grad()\n","\n","                        # forward\n","                        with torch.cuda.amp.autocast():\n","                            with torch.set_grad_enabled(phase == 'train'):\n","                                outputs = model(inputs)\n","                            if type(outputs) is tuple:\n","                                outputs = outputs[0]\n","                            loss = self.criterion(outputs, labels)\n","\n","                        # backward + optimize only if in training phase\n","                        if phase == 'train':\n","                            scaler.scale(loss).backward()\n","                            scaler.step(optimizer)\n","                            scaler.update()\n","\n","                            if batch_idx % self.nr_batch_report == 0:\n","                                wandb.log({\"loss\": loss.item()})\n","                                if self.lr_scheduler:\n","                                    wandb.log({\"lr\": self.lr_scheduler.get_last_lr()[-1]})\n","                                    self.lr_scheduler.step()\n","\n","                        # statistics\n","                        running_loss += loss.item() * inputs.size(0)\n","                        _, preds = torch.max(outputs, 1)\n","                        y_pred.extend(preds.tolist())\n","                        y_true.extend(labels.tolist())\n","\n","                    epoch_acc = balanced_accuracy_score(y_true, y_pred)\n","                    if phase == 'val':\n","                        wandb.log({\n","                            \"epoch_acc_val\": epoch_acc,\n","                        })\n","                    else:\n","                        epoch_loss = running_loss / self.dataset_sizes[phase]\n","                        wandb.log({\n","                            \"epoch_acc_train\": epoch_acc,\n","                            \"epoch_loss_train\": epoch_loss,\n","                        })\n","\n","                    checkpoint = {\n","                        'epoch': epoch + 1,\n","                        'state_dict': model.state_dict(),\n","                        'optimizer': optimizer.state_dict(),\n","                        'best_acc': self.best_acc\n","                    }\n","\n","                    # deep copy the model\n","                    if phase == 'val' and epoch_acc > self.best_acc:\n","                        save_ckp(checkpoint, True, \"checkpoint\", 'best_model', i)\n","                        self.best_acc = epoch_acc\n","                        wandb.log({\n","                            \"best_acc_val\": self.best_acc\n","                        })\n","                    save_ckp(checkpoint, False, \"checkpoint\", 'best_model', i)\n","            del model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-26T07:57:00.298219Z","iopub.status.busy":"2023-03-26T07:57:00.297234Z","iopub.status.idle":"2023-03-26T08:04:05.892513Z","shell.execute_reply":"2023-03-26T08:04:05.890150Z","shell.execute_reply.started":"2023-03-26T07:57:00.298183Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","criterion = nn.CrossEntropyLoss()\n","torch.manual_seed(123)\n","model_name = \"dumitrescustefan/bert-base-romanian-cased-v1\"\n","dataset = SexismDataset(model_name, \"/kaggle/input/custom/train_data_final.csv\")\n","model = SexismDetectionModel(model_name, num_classes=5)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n","\n","if not os.path.exists(\"best_model\"):\n","    os.makedirs(\"best_model\")\n","    \n","if not os.path.exists(\"checkpoint\"):\n","    os.makedirs(\"checkpoint\")\n","\n","# if the program was interrupted we will resume from the last saved model\n","print('Type 0 to exit, 1 to start fresh, 2 from checkpoint')\n","inp = input()\n","if inp == '0':\n","    exit(0)\n","\n","trainer = ModelTrainer(device, model, criterion, optimizer, dataset,\n","                        resume_from_checkpoint=(inp == '2'), project_name=\"Sexism NLP Hackathon\",\n","                        architecture=\"Bert-Romanian SD\", num_epochs=3, batch_size=256, initial_lr=2e-5,\n","                        validation_split=0.2,\n","                        num_classes=5, weighted_sampler=True)\n","trainer.train_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model_name = \"dumitrescustefan/bert-base-romanian-cased-v1\"\n","model = SexismDetectionModel(model_name, num_classes=5).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n","model, optimizer, last_epoch, acc = load_ckp('best_model/best_model.pt', model, optimizer)\n","dataset = SexismDataset(model_name, '/kaggle/input/custom/test_data_final.csv', test=True)\n","\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=False, num_workers=0)\n","\n","to_label = {\n","    0: 'direct',\n","    1: 'descriptive',\n","    2: 'reporting',\n","    3: 'offensive',\n","    4: 'non-offensive'\n","}\n","\n","predictions = []\n","ids = [i for i in range(len(dataset))]\n","with torch.no_grad():\n","    for inp in dataloader:\n","        inp = inp.to(device)\n","        outputs = model(inp)\n","        if type(outputs) is tuple:\n","            outputs = outputs[0]\n","        _, preds = torch.max(outputs, 1)\n","        predictions.extend(preds.tolist())\n","\n","\n","pred = [to_label[pr] for pr in predictions]\n","output = pd.DataFrame({'Id': ids, 'Label': pred})\n","output.to_csv('submissionv_clean.csv', index=False)\n","print(\"Your submission was successfully saved!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-03-26T08:04:05.897762Z","iopub.status.idle":"2023-03-26T08:04:05.898633Z","shell.execute_reply":"2023-03-26T08:04:05.898367Z","shell.execute_reply.started":"2023-03-26T08:04:05.898335Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model_name = \"dumitrescustefan/bert-base-romanian-cased-v1\"\n","\n","to_label = {\n","    0: 'direct',\n","    1: 'descriptive',\n","    2: 'reporting',\n","    3: 'offensive',\n","    4: 'non-offensive'\n","}\n","\n","dataset = SexismDataset(model_name, '/kaggle/input/custom/test_data_nomentions_sanitized.csv', test=True)\n","\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=False, num_workers=0)\n","\n","pred_all = []\n","for i in range(6):\n","    model = SexismDetectionModel(model_name, num_classes=5).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n","    \n","    try:\n","        model, optimizer, last_epoch, acc = load_ckp(f'checkpoint/checkpoint{i}.pt', model, optimizer)\n","    \n","        predictions = []\n","        ids = [i for i in range(len(dataset))]\n","        with torch.no_grad():\n","            for inp in dataloader:\n","                inp = inp.to(device)\n","                outputs = model(inp)\n","                if type(outputs) is tuple:\n","                    outputs = outputs[0]\n","                _, preds = torch.max(outputs, 1)\n","                predictions.extend(preds.tolist())\n","\n","        del model\n","        pred_all.append(predictions)\n","        print('true')\n","    except:\n","        del model\n","        continue\n","    \n","pred_all_np = np.array(pred_all)\n","final_pred = []\n","for col in range(pred_all_np.shape[1]):\n","    unique, counts = np.unique(pred_all_np[:, col], return_counts=True)\n","    max_index = np.argmax(counts)\n","    max_freq_num = unique[max_index]\n","    final_pred.append(max_freq_num)\n","\n","pred = [to_label[pr] for pr in final_pred]\n","output = pd.DataFrame({'Id': ids, 'Label': pred})\n","output.to_csv('submissionv13.csv', index=False)\n","print(\"Your submission was successfully saved!\")\n","\n","\n","    "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
